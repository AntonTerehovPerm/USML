{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 3\n",
    "<center> Автор материала: Павел Нестеров (@mephistopheies).\n",
    "\n",
    "Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Домашняя работа №4\n",
    "## <center> Логистическая регрессия в задаче тегирования вопросов StackOverflow\n",
    "\n",
    "**Надо вывести формулы, где это просится (да, ручка и бумажка), заполнить код в клетках и выбрать ответы в [веб-форме](https://docs.google.com/forms/d/100c3Ek94UL-VRwXrN4lxCSnGjfJrl6Gc96G21DNCh4w).** \n",
    "<span style=\"color:red\"> </span>\n",
    "\n",
    "## 0. Описание задачи\n",
    "\n",
    "В этой домашней работе мы с вами изучим и запрограммируем модель для прогнозирования тегов по тексту вопроса на базе многоклассовой логистической регрессии. В отличие от обычной постановки задачи классификации (multiclass), в данном случае один пример может принадлежать одновременно к нескольким классам (multilabel). Мы будем реализовывать онлайн-версию алгоритма multilabel-классификации.\n",
    "\n",
    "Мы будем использовать небольшую выборку из протеггированных вопросов с сайта StackOverflow размером в 125 тысяч примеров (около 150 Мб, скачайте по [этой](https://drive.google.com/open?id=0B4bl7YMqDnViYVo0V2FubFVhMFE) ссылке).\n",
    "\n",
    "PS: Можно показать, что такая реализация совсем не эффективная и проще было бы использовать векторизированные вычисления. Для данного датасета так и есть. Но на самом деле подобные реализации используются в жизни, но естественно, написаны они не на Python. Например, в онлайн-моделях прогнозирования [CTR](https://en.wikipedia.org/wiki/Click-through_rate) юзеру показывается баннер, затем в зависимости от наличия клика происходит обновление параметров модели. В реальной жизни параметров модели может быть несколько сотен миллионов, а у юзера из этих ста миллионов от силы сто или тысяча параметров отличны от нуля, векторизировать такие вычисления не очень эффективно. Обычно все это хранится в огромных кластерах в in-memory базах данных, а обработка пользователей происходит распределенно.\n",
    "\n",
    "PS2:\n",
    "- в процессе решения домашней работы вам придется работать с текстом, и у вас может возникнуть желание сделать очевидный препроцессинг, например привести все слова в нижний регистр, в-общем **этого делать не нужно, если не оговорено заранее в задании**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# поменяйте на свой путь\n",
    "DS_FILE_NAME = '../data/stackoverflow_sample_125k.tsv'\n",
    "TAGS_FILE_NAME = '../data/top10_tags.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c#', 'c++', 'jquery', 'html', 'android', 'java', 'javascript', 'python', 'php', 'ios'}\n"
     ]
    }
   ],
   "source": [
    "top_tags = []\n",
    "with open(TAGS_FILE_NAME, 'r') as f:\n",
    "    for line in f:\n",
    "        top_tags.append(line.strip())\n",
    "top_tags = set(top_tags)\n",
    "print(top_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Многоклассовая логистическая регрессия\n",
    "\n",
    "Вспомним, как получается логистическая регрессия для двух классов $\\left\\{0, 1\\right\\}$, вероятность принадлежности объекта к классу $1$ выписывается по теореме Байеса:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = 1 \\mid \\textbf{x}\\right) &=& \\dfrac{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right) + p\\left(\\textbf{x} \\mid c = 0\\right)p\\left(c = 0\\right)} \\\\\n",
    "&=& \\dfrac{1}{1 + e^{-a}} = \\sigma\\left(a\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\textbf{x}$ – вектор признаков объекта\n",
    "- $\\sigma$ – обозначение функции логистического сигмоида при скалярном аргументе\n",
    "- $a = \\log \\frac{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\textbf{x} \\mid c = 0\\right)p\\left(c = 0\\right)} = \\sum_{i=0}^M w_i x_i$ – это отношение мы моделируем линейной функцией от признаков объекта и параметров модели\n",
    "\n",
    "Данное выражение легко обобщить до множества из $K$ классов, изменится только знаменатель в формуле Байеса. Запишем вероятность принадлежности объекта к классу $k$:\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = k \\mid \\textbf{x}\\right) &=& \\dfrac{p\\left(\\textbf{x} \\mid c = k\\right)p\\left(c = k\\right)}{\\sum_{i=1}^K p\\left(\\textbf{x} \\mid c = i\\right)p\\left(c = i\\right)} \\\\\n",
    "&=& \\dfrac{e^{z_k}}{\\sum_{i=1}^{K}e^{z_i}} = \\sigma_k\\left(\\textbf{z}\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\sigma_k$ – обозначение функции softmax при векторном аргументе\n",
    "- $z_k = \\log p\\left(\\textbf{x} \\mid c = k\\right)p\\left(c = k\\right) = \\sum_{i=0}^M w_{ki} x_i$ – это выражение моделируется линейной функцией от признаков объекта и параметров модели для класса $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделирования полного правдоподобия примера мы используем [категориальное распределение](https://en.wikipedia.org/wiki/Categorical_distribution), а лучше его логарифм (для удобства):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\mathcal{L} = \\log p\\left({\\textbf{x}, y}\\right) &=& \\log \\prod_{i=1}^K \\sigma_i\\left(\\textbf{z}\\right)^{y_i} \\\\\n",
    "&=& \\sum_{i=1}^K y_i \\log \\sigma_i\\left(\\textbf{z}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "Получается хорошо знакомая нам функция [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) (если домножить на $-1$). Правдоподобие нужно максимизировать, а, соответственно, перекрестную энтропию нужно минимизировать. Продифференцировав по параметрам модели, мы _легко_ получим правила обновления весов для градиентного спуска, **проделайте этот вывод, если вы его не делали** (если вы вдруг сдались, то на [этом](https://www.youtube.com/watch?v=-WiR16raQf4) видео есть разбор вывода, понимание этого вам понадобится для дальнейшего выполнения задания; если предпочитаете текст, то и он есть [тут](https://www.ics.uci.edu/~pjsadows/notes.pdf) и [тут](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} &=& x_m \\left(y_k - \\sigma_k\\left(\\textbf{z}\\right)\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "В стандартной формулировке получается, что вектор $\\left(\\sigma_1, \\sigma_2, \\ldots, \\sigma_K\\right)$ образует дискретное вероятностное распределение, т.е. $\\sum_{i=1}^K \\sigma_i = 1$. Но в нашей постановке задачи каждый пример может иметь несколько тегов или одновременно принадлежать к нескольким классам. Для этого мы немного изменим модель:\n",
    "- будем считать, что все теги независимы друг от друга, т.е. каждый исход – это логистическая регрессия на два класса (либо есть тег, либо его нет), тогда вероятность наличия тега у примера запишется следующим образом (каждый тег/класс как и в многоклассовой логрегрессии имеет свой набор параметров):\n",
    "$$\\large p\\left(\\text{tag}_k \\mid \\textbf{x}\\right) = \\sigma\\left(z_k\\right) = \\sigma\\left(\\sum_{i=1}^M w_{ki} x^i \\right)$$\n",
    "- наличие каждого тега мы будем моделировать с помощью <a href=\"https://en.wikipedia.org/wiki/Bernoulli_distribution\">распределения Бернулли</a>\n",
    "\n",
    "<font color=\"red\">Вопрос 1.</font> Ваше первое задание –  записать упрощенное выражение логарифма правдоподобия примера с признаками $\\textbf{x}$. Как правило, многие алгоритмы оптимизации имеют интерфейс для минимизации функции, мы последуем этой же традиции и домножим полученное выражение на $-1$, а во второй части выведем формулы для минимизации полученного выражения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. $\\large -\\mathcal{L} = -\\sum_{i=1}^M y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "2. $\\large -\\mathcal{L} = -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$ ** otvet **\n",
    "3. $\\large -\\mathcal{L} = -\\sum_{i=1}^K z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$\n",
    "4. $\\large -\\mathcal{L} = -\\sum_{i=1}^M z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вывод формулы обновления весов\n",
    "\n",
    "<font color=\"red\">Вопрос 2.</font> В качестве второго задания вам предоставляется возможность вывести формулу градиента для $-\\mathcal{L}$. Какой вид она будет иметь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(\\sigma\\left(z_k\\right) - y_k\\right)$\n",
    "2. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(y_k - \\sigma\\left(z_k\\right)\\right)$ ** otvet **\n",
    "3. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(\\sigma\\left(z_k\\right)x_m - y_k\\right)$\n",
    "4. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(y_k - \\sigma\\left(z_k\\right)x_m\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализация базовой модели\n",
    "\n",
    "Вам предлагается каркас класса модели, разберите его внимательно, обращайте внимание на комментарии. Затем заполните пропуски, запустите полученную модель и ответьте на проверочный вопрос.\n",
    "\n",
    "Как вы могли уже заметить, при обновлении веса $w_{km}$ используется значение признака $x_m$, который равен $0$, если слова с индексом $m$ нет в предложении, и больше нуля, если такое слово есть. В нашем случае, чтобы не пересчитывать [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) самим или с помощью [sklearn.feature_extraction.text.CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), мы будем идти по словам предложения в порядке их следования. Если какое-то слово встречается несколько раз, то мы добавляем его в аккумулятор со своим весом. В итоге получится то же самое, как если сначала посчитать количество одинаковых слов и домножить на соответствующий вес. Соответственно, при вычислении линейной комбинации $z$ весов модели и признаков примера необходимо учитывать только ненулевые признаки объекта.\n",
    "\n",
    "Подсказка:\n",
    "- если реализовывать вычисление сигмоида так же, как в формуле, то при большом отрицательном значении $z$ вычисление $e^{-z}$ превратится в очень большое число, которое вылетит за допустимые пределы\n",
    "- в то же время $e^{-z}$ от большого положительного $z$ будет нулем\n",
    "- воспользуйтесь свойствами функции $\\sigma$ для того, чтобы пофиксить эту ошибку и реализовать $\\sigma$ без риска overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = ...\n",
    "                    z = self._b[tag] # текущее значение w_0 для tag\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        # z += ...\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sigma = ...\n",
    "                    sigma = 1 / (1 + np.exp(-z)) if z >= 0 else 1 - 1 / (1 + np.exp(z))\n",
    "    \n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sample_loss += ...\n",
    "                    if y == 1:\n",
    "                        sample_loss += -1 * np.log(np.max([tolerance, sigma]))\n",
    "                    else:\n",
    "                        sample_loss += -1 * np.log(1 - np.min([1 - tolerance, sigma]))\n",
    " \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        # dLdw = ...\n",
    "                        dLdw = (y - sigma)\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55fd170ff0484f77b321a31bd0dc4b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 3min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# создадим эксемпляр модели и пройдемся по датасету\n",
    "model = LogRegressor()\n",
    "model.iterate_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, действительно ли значение отрицательного логарифмического правдоподобия уменьшалось. Так как мы используем стохастический градентный спуск, не стоит ожидать плавного падения функции ошибки. Мы воспользуемся скользящим средним с окном в 10 тысяч примеров, чтобы хоть как-то сгладить график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the loss function on the last 10k train samples: 20.04\n"
     ]
    }
   ],
   "source": [
    "print('Mean of the loss function on the last 10k train samples: %0.2f' % np.mean(model._loss[-35000:-25000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 3.</font>\n",
    "Вычислите среднее значение функции стоимости на последних 10 000 примеров тренировочного набора, к какому из значений ваш ответ ближе всего?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 17.54\n",
    "2. 18.64\n",
    "3. 19.74 ** otvet **\n",
    "4. 20.84 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Тестирование модели\n",
    "\n",
    "В базовой модели первые 100 000 строк используются для обучения, а оставшиеся – для тестирования. Как вы можете заметить, значение отрицательного логарифмического правдоподобия не очень информативно, хоть и позволяет сравнивать разные модели. В качестве четвертого задания вам необходимо модифицировать базовую модель таким образом, чтобы метод `iterate_file` возвращал значение _точности_ на тестовой части набора данных. \n",
    "\n",
    "Точность определим следующим образом:\n",
    "- считаем, что тег у вопроса присутствует, если спрогнозированная вероятность тега больше 0.9\n",
    "- точность одного примера расчитывается как [коэффициент Жаккара](https://ru.wikipedia.org/wiki/Коэффициент_Жаккара) между множеством настоящих тегов и предсказанных моделью\n",
    "  - например, если у примера настоящие теги ['html', 'jquery'], а по версии модели ['ios', 'html', 'java'], то коэффициент Жаккара будет равен |['html', 'jquery'] $\\cap$ ['ios', 'html', 'java']| / |['html', 'jquery'] $\\cup$ ['ios', 'html', 'java']| = |['html']| / |['jquery', 'ios', 'html', 'java']| = 1/4\n",
    "- метод `iterate_file` возвращает **среднюю** точность на тестовом наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    def __init__(self, tags=top_tags):\n",
    "        self._vocab = {}\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        self._tags = set(tags)    \n",
    "    \n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     predicted_level=0.9):\n",
    "        \n",
    "        self._loss = []\n",
    "        self._accuracy = []\n",
    "        n = 0\n",
    "        \n",
    "        with open(fname, 'r') as f: \n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                sentence = sentence.split(' ')\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                sample_loss = 0\n",
    "                \n",
    "                #предсказанные моделью теги для текущего sample (на тестовой части)\n",
    "                predicted_tags = set()\n",
    "\n",
    "                for tag in self._tags:\n",
    "                    y = int(tag in tags)\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    sigma = 1 / (1 + np.exp(-z)) if z >= 0 else 1 - 1 / (1 + np.exp(z))\n",
    "        \n",
    "                    if y == 1:\n",
    "                        sample_loss += -1 * np.log(np.max([tolerance, sigma]))\n",
    "                    else:\n",
    "                        sample_loss += -1 * np.log(1 - np.min([1 - tolerance, sigma]))\n",
    "                    \n",
    "                    if n < top_n_train:\n",
    "                        dLdw = (y - sigma)\n",
    "\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    else:\n",
    "                        # мы в тестовой части выборки, считаем accuracy\n",
    "                        if sigma > predicted_level:\n",
    "                            predicted_tags.add(tag)\n",
    "                            \n",
    "                if n >= top_n_train:\n",
    "                    self._accuracy.append(self._jaccard_index(predicted_tags, tags))                    \n",
    "                    \n",
    "                n += 1                        \n",
    "                self._loss.append(sample_loss)\n",
    "            \n",
    "        return(np.mean(self._accuracy))\n",
    "    \n",
    "    @staticmethod\n",
    "    def _jaccard_index(a: set, b: set):        \n",
    "        return len(a & b) / len(a | b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5008c61c5dfa40238bed38c2f95c1336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.58\n",
      "Wall time: 3min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "# выведем полученное значение с точностью до двух знаков\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 4.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.39\n",
    "2. 0.49\n",
    "3. 0.59 ** otvet **\n",
    "4. 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. $L_2$-регуляризация\n",
    "\n",
    "В качестве пятого задания вам необходимо добавить в класс `LogRegressor` поддержку $L_2$-регуляризации. В методе `iterate_file` должен появиться параметр `lmbda=0.01` со значением по умолчанию. С учетом регуляризации новая функция стоимости примет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(\\textbf W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\frac{\\lambda}{2} \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2\n",
    "\\end{array}$$\n",
    "\n",
    "Градиент первого члена суммы мы уже вывели, а для второго он имеет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial}{\\partial w_{ki}} \\frac{\\lambda}{2} R\\left(\\textbf W\\right) &=& \\lambda w_{ki}\n",
    "\\end{array}$$\n",
    "\n",
    "Если мы на каждом примере будем делать честное обновление всех весов, то все очень замедлится, ведь нам придется на каждой итерации пробегать по всем словам словаря. В ущерб теоретической корректности мы используем грязный трюк: будем регуляризировать только те слова, которые присутствуют в текущем предложении. Не забывайте, что смещение (bias) не регуляризируется. `sample_loss` тоже должен остаться без изменений.\n",
    "\n",
    "Замечание:\n",
    "- не забудьте, что нужно учитывать регуляризацию слова в градиентном шаге только один раз\n",
    "- условимся, что учитываем регуляризацию только при первой встрече слова\n",
    "- если бы мы считали сначала bag-of-words, то мы бы в цикле шли по уникальным словам, но т.к. мы этого не делаем, приходится выкручиваться (еще одна жертва богу online-моделей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    def __init__(self, tags=top_tags):\n",
    "        self._vocab = {}\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        self._tags = set(tags)    \n",
    "    \n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     predicted_level=0.9,\n",
    "                     lmbda=0.01):\n",
    "        \n",
    "        self._loss = []\n",
    "        self._accuracy = []\n",
    "        n = 0\n",
    "        \n",
    "        with open(fname, 'r') as f: \n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                sentence = sentence.split(' ')\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                sample_loss = 0\n",
    "                \n",
    "                #предсказанные моделью теги для текущего sample (на тестовой части)\n",
    "                predicted_tags = set()\n",
    "\n",
    "                for tag in self._tags:\n",
    "                    y = int(tag in tags)\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                            \n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    sigma = 1 / (1 + np.exp(-z)) if z >= 0 else 1 - 1 / (1 + np.exp(z))\n",
    "        \n",
    "                    if y == 1:\n",
    "                        sample_loss += -1 * np.log(np.max([tolerance, sigma]))\n",
    "                    else:\n",
    "                        sample_loss += -1 * np.log(1 - np.min([1 - tolerance, sigma]))\n",
    "                    \n",
    "                    if n < top_n_train:\n",
    "                        unique_words = set()\n",
    "                        dLdw = (y - sigma) \n",
    "\n",
    "                        for word in sentence:\n",
    "                            r = 0 if word in unique_words else self._w[tag][self._vocab[word]]                            \n",
    "                            unique_words.add(word)\n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*(dLdw - lmbda*r)\n",
    "                            \n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    else:\n",
    "                        # мы в тестовой части выборки, считаем accuracy\n",
    "                        if sigma > predicted_level:\n",
    "                            predicted_tags.add(tag)\n",
    "                            \n",
    "                if n >= top_n_train:\n",
    "                    self._accuracy.append(self._jaccard_index(predicted_tags, tags))                    \n",
    "                    \n",
    "                n += 1                        \n",
    "                self._loss.append(sample_loss)\n",
    "            \n",
    "        return(np.mean(self._accuracy))\n",
    "    \n",
    "    @staticmethod\n",
    "    def _jaccard_index(a: set, b: set):        \n",
    "        return len(a & b) / len(a | b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68521d15d8854f0191b7330cdbb8fcc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.55\n",
      "Wall time: 4min 50s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 5.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.3\n",
    "2. 0.35\n",
    "3. 0.4\n",
    "4. 0.52 ** otvet **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ElasticNet регуляризация, вывод\n",
    "Помимо $L_2$ регуляризации, часто используется $L_1$ регуляризация.\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(\\textbf W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right|\n",
    "\\end{array}$$\n",
    "\n",
    "Если линейно объединить $L_1$ и $L_2$ регуляризацию, то полученный тип регуляризации называется ElasticNet:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\lambda R\\left(\\textbf W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\left(\\gamma \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2 + \\left(1 - \\gamma\\right) \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right| \\right)\n",
    "\\end{array}$$\n",
    "- где $\\gamma \\in \\left[0, 1\\right]$\n",
    "\n",
    "В качестве шестого вопроса вам предлагается вывести формулу градиента ElasticNet регуляризации (не учитывая $-\\mathcal{L}$). \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(\\textbf W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) w_{ki}\\right)$ \n",
    "2. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(\\textbf W\\right) = \\lambda \\left(2 \\gamma \\left|w_{ki}\\right| + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "3. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(\\textbf W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$ ** otvet **\n",
    "4. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(\\textbf W\\right) = \\lambda \\left(\\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Регуляризация ElasticNet , реализация\n",
    "\n",
    "В качестве седьмой задачи вам предлается изменить класс `LogRegressor` таким образом, чтобы метод `iterate_file` принимал два параметра со значениями по умолчанию `lmbda=0.0002` и `gamma=0.1`. Сделайте один проход по датасету с включенной `ElasticNet`-регуляризацией и заданными значениями по умолчанию и ответьте на вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    def __init__(self, tags=top_tags):\n",
    "        self._vocab = {}\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        self._tags = set(tags)    \n",
    "    \n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     predicted_level=0.9,\n",
    "                     lmbda=0.0002,\n",
    "                     gamma=0.1):\n",
    "        \n",
    "        self._loss = []\n",
    "        self._accuracy = []\n",
    "        n = 0\n",
    "        \n",
    "        with open(fname, 'r') as f: \n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                sentence = sentence.split(' ')\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                sample_loss = 0\n",
    "                \n",
    "                #предсказанные моделью теги для текущего sample (на тестовой части)\n",
    "                predicted_tags = set()\n",
    "\n",
    "                for tag in self._tags:\n",
    "                    y = int(tag in tags)\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                            \n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    sigma = 1 / (1 + np.exp(-z)) if z >= 0 else 1 - 1 / (1 + np.exp(z))\n",
    "        \n",
    "                    if y == 1:\n",
    "                        sample_loss += -1 * np.log(np.max([tolerance, sigma]))\n",
    "                    else:\n",
    "                        sample_loss += -1 * np.log(1 - np.min([1 - tolerance, sigma]))\n",
    "                    \n",
    "                    if n < top_n_train:\n",
    "                        unique_words = set()\n",
    "                        dLdw = (y - sigma) \n",
    "\n",
    "                        for word in sentence:\n",
    "                            w_k_i = self._w[tag][self._vocab[word]]\n",
    "                            r = 0 if word in unique_words else \\\n",
    "                                2*gamma*w_k_i + (1.0 - gamma)*np.sign(w_k_i)  \n",
    "                                \n",
    "                            unique_words.add(word)\n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*(dLdw - lmbda*r)\n",
    "                            \n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    else:\n",
    "                        # мы в тестовой части выборки, считаем accuracy\n",
    "                        if sigma > predicted_level:\n",
    "                            predicted_tags.add(tag)\n",
    "                            \n",
    "                if n >= top_n_train:\n",
    "                    self._accuracy.append(self._jaccard_index(predicted_tags, tags))                    \n",
    "                    \n",
    "                n += 1                        \n",
    "                self._loss.append(sample_loss)\n",
    "            \n",
    "        return(np.mean(self._accuracy))\n",
    "    \n",
    "    @staticmethod\n",
    "    def _jaccard_index(a: set, b: set):        \n",
    "        return len(a & b) / len(a | b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 7.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.59 ** otvet **\n",
    "2. 0.69\n",
    "3. 0.79\n",
    "4. 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Самые важные слова для тега\n",
    "\n",
    "Прелесть линейных моделей в том, что они легко интерпретируемы. Вам предлагается вычислить, какие слова вносят наибольший вклад в вероятность появления каждого из тегов. А затем ответьте на контрольный вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c# : binding, writeline, net, foreach, sender\n",
      "c++ : c++, std, cout, _defaultimage, const\n",
      "jquery : jquery, ready, val, ajax, click\n",
      "html : html, some, quot, img, font\n",
      "android : android, imgsrv, 29297, ff, quot\n",
      "java : println, java, artifactid, quot, servlet\n",
      "javascript : javascript, 125, getelementbyid, var, angular\n",
      "python : python, def, py, np, django\n",
      "php : php, echo, x5c, _post, 125\n",
      "ios : ios, nsstring, nil, corefoundation, xcode\n"
     ]
    }
   ],
   "source": [
    "model._vocab_inv = dict([(v, k) for (k, v) in model._vocab.items()])\n",
    "\n",
    "for tag in model._tags:\n",
    "    print(tag, ':', ', '.join([model._vocab_inv[k] for (k, v) in \n",
    "                               sorted(model._w[tag].items(), \n",
    "                                      key=lambda t: t[1], \n",
    "                                      reverse=True)[:5]]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 8.</font> Для многих тегов наличие самого тега в предложении является важным сигналом, у многих сам тег является самым сильным сигналом, что не удивительно. Для каких из тегов само название тега не входит в топ-5 самых важных?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. c# ** otvet **\n",
    "2. javascript\n",
    "3. jquery\n",
    "4. android"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. Сокращаем размер словаря\n",
    "Сейчас количество слов в словаре – 519290, если бы это была выборка из 10 миллионов вопросов с сайта StackOverflow, то размер словаря был бы миллионов 10. Регуляризировать модель можно не только изящно математически, но и топорно, например, ограничить размер словаря. Вам предоставляется возможность внести следующие изменения в класс `LogRegressor`:\n",
    "- добавить в метод `iterate_file` еще один аргумент со значением по умолчанию `update_vocab=True`\n",
    "- при `update_vocab=True` разрешать добавлять слова в словарь в режиме обучения\n",
    "- при `update_vocab=False` игнорировать слова не из словаря\n",
    "- добавить в класс метод `filter_vocab(n=10000)`, который оставит в словаре только топ-n самых популярных слов, используя данные из ``train``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "class LogRegressor():\n",
    "    def __init__(self, tags=top_tags):\n",
    "        self._vocab = {}\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        self._tags = set(tags)\n",
    "        \n",
    "        self._word_counter = Counter()\n",
    "        \n",
    "    def filter_vocab(self, n=10000):\n",
    "        top_words = {k for k,v in self._word_counter.most_common(n)}\n",
    "        self._vocab = {k:v for k ,v in self._vocab.items() if k in top_words}\n",
    "        \n",
    "    \n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     predicted_level=0.9,\n",
    "                     lmbda=0.0002,\n",
    "                     gamma=0.1,\n",
    "                     update_vocab=True):\n",
    "        \n",
    "        self._loss = []\n",
    "        self._accuracy = []\n",
    "        n = 0\n",
    "        \n",
    "        with open(fname, 'r') as f: \n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                sentence = sentence.split(' ')\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # Обновляем счетчики слов\n",
    "                if n < top_n_train:\n",
    "                    self._word_counter.update(sentence)\n",
    "                \n",
    "                sample_loss = 0\n",
    "                \n",
    "                #предсказанные моделью теги для текущего sample (на тестовой части)\n",
    "                predicted_tags = set()\n",
    "\n",
    "                for tag in self._tags:\n",
    "                    y = int(tag in tags)\n",
    "                    z = self._b[tag]\n",
    "                    \n",
    "                    if update_vocab:\n",
    "                        for word in sentence:\n",
    "                            if n >= top_n_train and word not in self._vocab:\n",
    "                                continue\n",
    "                            if word not in self._vocab:\n",
    "                                self._vocab[word] = len(self._vocab)\n",
    "                                \n",
    "                    for word in sentence:\n",
    "                        if word in self._vocab:\n",
    "                            z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    sigma = 1 / (1 + np.exp(-z)) if z >= 0 else 1 - 1 / (1 + np.exp(z))\n",
    "        \n",
    "                    if y == 1:\n",
    "                        sample_loss += -1 * np.log(np.max([tolerance, sigma]))\n",
    "                    else:\n",
    "                        sample_loss += -1 * np.log(1 - np.min([1 - tolerance, sigma]))\n",
    "                    \n",
    "                    if n < top_n_train:\n",
    "                        unique_words = set()\n",
    "                        dLdw = (y - sigma) \n",
    "\n",
    "                        for word in sentence:\n",
    "                            if word in self._vocab:\n",
    "                                w_k_i = self._w[tag][self._vocab[word]]\n",
    "                                r = 0 if word in unique_words else \\\n",
    "                                    2*gamma*w_k_i + (1.0 - gamma)*np.sign(w_k_i)  \n",
    "\n",
    "                                unique_words.add(word)\n",
    "                                self._w[tag][self._vocab[word]] -= -learning_rate*(dLdw - lmbda*r)\n",
    "                            \n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    else:\n",
    "                        # мы в тестовой части выборки, считаем accuracy\n",
    "                        if sigma > predicted_level:\n",
    "                            predicted_tags.add(tag)\n",
    "                            \n",
    "                if n >= top_n_train:\n",
    "                    self._accuracy.append(self._jaccard_index(predicted_tags, tags))                    \n",
    "                    \n",
    "                n += 1                        \n",
    "                self._loss.append(sample_loss)\n",
    "            \n",
    "        return(np.mean(self._accuracy))\n",
    "    \n",
    "    @staticmethod\n",
    "    def _jaccard_index(a: set, b: set):        \n",
    "        return len(a & b) / len(a | b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74c7edb642b48889d2b56abdb37047b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n",
      "Exception ignored in: 'zmq.backend.cython.message.Frame.__dealloc__'\n",
      "Traceback (most recent call last):\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc\n",
      "    PyErr_CheckSignals()\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-54c55b25dec6>\u001b[0m in \u001b[0;36miterate_file\u001b[1;34m(self, fname, top_n_train, total, learning_rate, tolerance, predicted_level, lmbda, gamma, update_vocab)\u001b[0m\n\u001b[0;32m     78\u001b[0m                                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munique_words\u001b[0m \u001b[1;32melse\u001b[0m                                     \u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mw_k_i\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_k_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                                 \u001b[0munique_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdLdw\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model._vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оставим только топ 10 000 слов\n",
    "model.filter_vocab(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2855db6c9f87486f8efd98c7906c3312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "# сделаем еще одну итерацию по датасету, Скорость обучения должна увеличиться в 10 раз\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 9.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.48\n",
    "2. 0.58\n",
    "3. 0.68 ** otvet **\n",
    "4. 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Прогнозирование тегов для новых вопросов\n",
    "\n",
    "В завершение этого задания вам предлагается реализовать метод `predict_proba`, который принимает строку, содержащую вопрос, а возвращает список предсказанных тегов вопроса с их вероятностями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "class LogRegressor():\n",
    "    def __init__(self, tags=top_tags):\n",
    "        self._vocab = {}\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        self._tags = set(tags)\n",
    "        \n",
    "        self._word_counter = Counter()\n",
    "        \n",
    "    def filter_vocab(self, n=10000):\n",
    "        top_words = {k for k,v in self._word_counter.most_common(n)}\n",
    "        self._vocab = {k:v for k ,v in self._vocab.items() if k in top_words}\n",
    "        \n",
    "    \n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     predicted_level=0.9,\n",
    "                     lmbda=0.0002,\n",
    "                     gamma=0.1,\n",
    "                     update_vocab=True):\n",
    "        \n",
    "        self._loss = []\n",
    "        self._accuracy = []\n",
    "        n = 0\n",
    "        \n",
    "        with open(fname, 'r') as f: \n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                sentence = sentence.split(' ')\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # Обновляем счетчики слов\n",
    "                if n < top_n_train:\n",
    "                    self._word_counter.update(sentence)\n",
    "                \n",
    "                sample_loss = 0\n",
    "                \n",
    "                #предсказанные моделью теги для текущего sample (на тестовой части)\n",
    "                predicted_tags = set()\n",
    "\n",
    "                for tag in self._tags:\n",
    "                    y = int(tag in tags)\n",
    "                    z = self._b[tag]\n",
    "                    \n",
    "                    if update_vocab:\n",
    "                        for word in sentence:\n",
    "                            if n >= top_n_train and word not in self._vocab:\n",
    "                                continue\n",
    "                            if word not in self._vocab:\n",
    "                                self._vocab[word] = len(self._vocab)\n",
    "                                \n",
    "                    for word in sentence:\n",
    "                        if word in self._vocab:\n",
    "                            z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    sigma = 1 / (1 + np.exp(-z)) if z >= 0 else 1 - 1 / (1 + np.exp(z))\n",
    "        \n",
    "                    if y == 1:\n",
    "                        sample_loss += -1 * np.log(np.max([tolerance, sigma]))\n",
    "                    else:\n",
    "                        sample_loss += -1 * np.log(1 - np.min([1 - tolerance, sigma]))\n",
    "                    \n",
    "                    if n < top_n_train:\n",
    "                        unique_words = set()\n",
    "                        dLdw = (y - sigma) \n",
    "\n",
    "                        for word in sentence:\n",
    "                            if word in self._vocab:\n",
    "                                w_k_i = self._w[tag][self._vocab[word]]\n",
    "                                r = 0 if word in unique_words else \\\n",
    "                                    2*gamma*w_k_i + (1.0 - gamma)*np.sign(w_k_i)  \n",
    "\n",
    "                                unique_words.add(word)\n",
    "                                self._w[tag][self._vocab[word]] -= -learning_rate*(dLdw - lmbda*r)\n",
    "                            \n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    else:\n",
    "                        # мы в тестовой части выборки, считаем accuracy\n",
    "                        if sigma > predicted_level:\n",
    "                            predicted_tags.add(tag)\n",
    "                            \n",
    "                if n >= top_n_train:\n",
    "                    self._accuracy.append(self._jaccard_index(predicted_tags, tags))                    \n",
    "                    \n",
    "                n += 1                        \n",
    "                self._loss.append(sample_loss)\n",
    "            \n",
    "        return(np.mean(self._accuracy))\n",
    "    \n",
    "    @staticmethod\n",
    "    def _jaccard_index(a: set, b: set):        \n",
    "        return len(a & b) / len(a | b)\n",
    "    \n",
    "    def predict_proba(self, sentence):\n",
    "        p = {}\n",
    "        sentence = sentence.split(' ')\n",
    "        for tag in self._tags:\n",
    "            z = self._b[tag]\n",
    "            for word in sentence:\n",
    "                if word not in self._vocab:\n",
    "                    continue\n",
    "                z += self._w[tag][self._vocab[word]]\n",
    "            sigma = 1 / (1 + np.exp(-z)) if z >= 0 else 1 - 1 / (1 + np.exp(z))\n",
    "            p[tag] = sigma\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "model.filter_vocab(n=10000)\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = (\"I want to improve my coding skills, so I have planned write \" +\n",
    "            \"a Mobile Application.need to choose between Apple's iOS or Google's Android.\" +\n",
    "            \" my background: I have done basic programming in .Net,C/C++,Python and PHP \" +\n",
    "            \"in college, so got OOP concepts covered. about my skill level, I just know \" +\n",
    "            \"concepts and basic syntax. But can't write complex applications, if asked :(\" +\n",
    "            \" So decided to hone my skills, And I wanted to know which is easier to \" +\n",
    "            \"learn for a programming n00b. A) iOS which uses Objective C B) Android \" + \n",
    "            \"which uses Java. I want to decide based on difficulty \" + \n",
    "            \"level\").lower().replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(model.predict_proba(sentence).items(), \n",
    "       key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 10.</font> Отметьте все теги, ассоциирующиеся с данным вопросом, если порог принятия равен $0.9$. То есть считаем, что вопросу надо поставить некоторый тег, если вероятность его появления, предсказанная моделью, больше или равна 0.9. \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. android\n",
    "2. ios ** otvet **\n",
    "3. php\n",
    "4. java"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
