{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_standart = pd.read_csv('year_transaction_standart.csv')\n",
    "#data_standart_year_1 = pd.read_csv('year_transaction_1.csv')\n",
    "#data_standart_year_2_test = pd.read_csv('year_transaction_2.csv')\n",
    "ideal_y_vector = pd.read_csv('terminals.csv',header=None)\n",
    "ideal_y_vector.columns=['nomber_terminal','money']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_y_vector.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_standart.shape[0]\n",
    "data_standart_year_1.shape[0]\n",
    "data_standart_year_2_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tn\n",
    "def rewrite_file(name_file):\n",
    "    '''т.к. изначальная бд была представленна не очень корректно в плане времени и даты(одним столбцом), \n",
    "    что крайне неудобно было при сортировке, было принято решение, улучшить DataFrame'''\n",
    "    f = open(name_file,'r')\n",
    "    g = open('new_'+name_file,'w')\n",
    "    for line in tn(f):\n",
    "        if line[0] == ',':\n",
    "            p = line[1:len(line)].split(',')\n",
    "            g.write(p[0]+','+p[1]+','+'month'+','+'day'+','+p[3]+','+p[4]+','+p[5]+','+p[6]+','+p[7])\n",
    "            g.write('\\n')\n",
    "        else:\n",
    "            p = line[1:len(line)].split(',')\n",
    "            y = p[3].split('.')\n",
    "            g.write(p[1]+','+p[2]+','+y[1]+','+y[0]+','+p[4]+','+p[5]+','+p[6]+','+p[7]+','+p[8])\n",
    "            g.write('\\n')\n",
    "    f.close()\n",
    "    g.close()\n",
    "    print('запись завершена')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Подготовка выборк – для этого необходимо рассчитать отток загружаемых в банкомат средств: все транзакции с меткой operation “-”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! мы не берем транзакции '/', т.к. они лишь перенос средств с одного абстрактного счета на другой, без изятия средств банкомата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#комп не выдерживает загрузки 3-х файлов сразу\n",
    "array_data = ['year_transaction_standart.csv','year_transaction_1.csv','year_transaction_2.csv']\n",
    "for i,x in tn(enumerate(array_data)):\n",
    "    rewrite_file(x)#изменение DataFrame\n",
    "    new_data_standart = pd.read_csv('new_'+x)\n",
    "    #data = new_data_standart[new_data_standart['operation'] == '-'].groupby(['nomber_terminal','month'])['money'].sum()\n",
    "    data = new_data_standart[new_data_standart['operation'] == '-'].groupby(['nomber_terminal'])['money'].sum()\n",
    "    data.to_csv('lose_money_'+str(i)+'.csv')\n",
    "print('Все приготовления и приведения БД в порядок завершены!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Проверка всех выборк в сравнении с идеальной выборкой по банкоматам: Точность ≈ %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#1 год\n",
    "data_1 = pd.read_csv('lose_money_0.csv',header=None)\n",
    "data_1.columns=['nomber_terminal','money']\n",
    "#data_1.columns=['nomber_terminal','month','money']\n",
    "data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 год\n",
    "data_2 = pd.read_csv('lose_money_1.csv',header=None)\n",
    "data_2.columns=['nomber_terminal','money']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 год\n",
    "data_3 = pd.read_csv('lose_money_2.csv',header=None)\n",
    "data_3.columns=['nomber_terminal','money']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нас не интересует, если денег из банкомата снимает меньше нормы, а вот если есть превышение, тогда это считается ошибкой.\n",
    "Чем ниже процент, тем ниже общая ошибка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_error(data,data_ideal):\n",
    "    data_new = []\n",
    "    kol = 0\n",
    "    for x in range(data.shape[0]-1):\n",
    "        if data_ideal.loc[x][1] - data.loc[x][1] < 0 : kol+=1\n",
    "        #data_new.append([x,data_ideal.loc[x][1] - data.loc[x][1]])\n",
    "    print('Ошибка '+str(100/data_ideal.shape[0]*kol)+' %') \n",
    "    #return data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В данном случае процент ошибки = 0, это значит что идеальное наполнение банкоматов устанавливалось по этому году\n",
    "accuracy_error(data_1,ideal_y_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Проверка 2 и 3 года выборки в сравнении с идеальной(1) выборкой по банкоматам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_error(data_1,data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_error(data_1,data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_error(data_2,data_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод\n",
    "    Самую высокую ошибку 50.2% от стандартного года(data_1) имеет 2 год(data_2) поэтому стоит рассмотреть именно его в сравнении со стандартным, для понимания протекающих изменений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Проверка разницы транзакций стандартного года с последующими"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "new_data_standart_1 = pd.read_csv('new_year_transaction_standart.csv')\n",
    "new_data_standart_2 = pd.read_csv('new_year_transaction_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Слишком долгие вычисления, но без нагрузки памяти и перегрузки оперативы\n",
    "def check_transaction(data,data_1, Return_data = False):\n",
    "    distortion = 0\n",
    "    percent = 0\n",
    "    for x in tn(range(data.shape[0])):\n",
    "        if sum( data.loc[x] == data_1.loc[x] ) != 9:\n",
    "            array_of_distortion.append([data.loc[x],data_1.loc[x]])\n",
    "            distortion+=1\n",
    "        #else:\n",
    "            #print(s,':',data.loc[x])\n",
    "    percent = 100/data.shape[0]*distortion\n",
    "    print(\"Отклонение транзакций – {0}%; Измененных {1}\".format(percent,distortion))\n",
    "    if Return_data:\n",
    "        return array_of_distortion,distortion,percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_transaction(new_data_standart_1,new_data_standart_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Исключения. Создание нового Data Frame – отклоняющиеся транзакции(которые изменены для проверяемых годов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Данные действия в функции серьезно нагружают вычислительные мощности компьютера и забивают оперативную память\n",
    "def check_transaction(data,data_1, Return_data = False):\n",
    "    common_cols = data.columns.tolist()\n",
    "    array_copy = pd.merge(data, data_1, on=common_cols, how='inner')\n",
    "    array_of_distortion = data_1[~data_1['nomber_transaction'].isin(array_copy['nomber_transaction'])]\n",
    "    array_of_distortion_1 = data[~data['nomber_transaction'].isin(array_copy['nomber_transaction'])]\n",
    "    distortion = array_of_distortion.shape[0]\n",
    "    percent = 100/data.shape[0]*distortion\n",
    "    print(\"Отклонение транзакций – {0}%; Измененных {1}\".format(percent,distortion))\n",
    "    if Return_data:\n",
    "        return array_copy,array_of_distortion,array_of_distortion_1,distortion,percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_copy,array_of_distortion,array_of_distortion_1,distortion,percent = check_transaction(new_data_standart_1,new_data_standart_2, Return_data = True)\n",
    "array_of_distortion.to_csv('array_of_distortion.csv')\n",
    "array_of_distortion_1.to_csv('array_of_distortion_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отклонение транзакций – 10%; Измененных 950.673"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним таким же образом стандартный и 3 год, а также 2 и 3. На самом деле, этого можно не делать, ведь сравнение стандартного и 2 года дают практический исчерпывающий ответ, но для определения зависимостей, мы все-таки их рассмотрим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "new_data_standart_2 = pd.read_csv('new_year_transaction_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_transaction(new_data_standart_1,new_data_standart_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "new_data_standart_1 = pd.read_csv('new_year_transaction_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_transaction(new_data_standart_2,new_data_standart_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Изучение искажений\n",
    "<ol>\n",
    "    <li>Nomber_terminal – 2%</li>\n",
    "    <li>Nomber_transaction – не влияет на транзакцию</li>\n",
    "    <li>Day_time – 70% ~ 30%</li>\n",
    "    <li>Type_transaction and operation – 20%</li>\n",
    "    <li>Id_card_1 and id_card_2 – 3%</li>\n",
    "    <li>Money – 5%</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>Группировка всех транзакций по пользователям, выделение % искажения транзакций для каждого пользователя.</div>\n",
    "<div>Для того, чтобы решить эту задачу, нам нужно узнать количество всех транзакций за 2 года для каждого пользователя,</div>\n",
    "<div>узнать количество транзакций измененных на следующий год(неважно, какое искажение было задействованно)</div>\n",
    "<div>После чего узнать % искаженных транзакций от общего количества у каждого пользователя.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 года\n",
    "%%time\n",
    "new_data_standart_1 = pd.read_csv('new_year_transaction_standart.csv')\n",
    "new_data_standart_2 = pd.read_csv('new_year_transaction_1.csv')\n",
    "#2 датафрейма с искажаемыми транзакциями, полученные из пункта 4 array_of_distortion,array_of_distortion_1\n",
    "array_of_distortion = pd.read_csv('array_of_distortion.csv')\n",
    "array_of_distortion_1 = pd.read_csv('array_of_distortion_1.csv')\n",
    "#пустой DataFrame куда и будем складывать все вычисления data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>выбираем всех пользователей из 4-х DataFrame, считая сколько раз они встречаются, после чего объединяем их по индексу id_user</p>\n",
    "<p>после объединения, делаем новыую индексацию, и задаеи название колонок</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data=pd.concat([new_data_standart_1['id_card_1'].value_counts(),new_data_standart_2['id_card_1'].value_counts(),array_of_distortion['id_card_1'].value_counts(),array_of_distortion_1['id_card_1'].value_counts()], axis=1).reset_index(), \n",
    "                    columns=['id_user','year_1_all_transaction','year_2_all_transaction','year_1_lose_transaction','year_2_lose_transaction'])\n",
    "data.stack().apply(pd.to_numeric, errors='ignore').fillna(0).unstack() #заменяю пустые None ячейки на 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "создаем 3 новых столбца \n",
    "1. % искажений 1 года к 1 году\n",
    "2. % искажений 2 года к 2 году\n",
    "3. от общего процент искажений(2 новых столбеца 1 + 2 год)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['percent_year_1'] = data.apply(lambda row: 100/row.year_1_all_transaction*row.year_1_lose_transaction, axis=1)\n",
    "data['percent_year_1'] = data.apply(lambda row: 100/row.year_1_all_transaction*row.year_1_lose_transaction, axis=1)\n",
    "data['sum_year'] = data.apply(lambda row: row.year_1_all_transaction + row.year_2_all_transaction, axis=1)\n",
    "data['sum_lose'] = data.apply(lambda row: row.year_1_lose_transaction + row.year_2_lose_transaction, axis=1)\n",
    "data['percent_year_1'] = data.apply(lambda row: 100/row.sum_year*row.sum_lose, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Не забываем также учитывать пользователей с одной единственной транзакцией, которых нет в следующем году(отказались от наших услуг, мошенники, которые используют счета для перевода и отмывания средств, пользователи использующие другие банковские системы и др.) смотрите 'дополнительно' в конце notebook</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сложение средств из неизменяемых транзакций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя функцию check_transaction, мы получили DataFrame array_copy в котором храняться одинаковые пересекающиеся транзакции 2-х лет, поэтому сравним его с идеальным годом и посмотрим какой процент ошибок наполнения возникает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_copy.to_csv('array_copy.csv')\n",
    "#data = array_copy[array_copy['operation'] == '-'].groupby(['nomber_terminal','month'])['money'].sum()\n",
    "data = array_copy[array_copy['operation'] == '-'].groupby(['nomber_terminal'])['money'].sum()\n",
    "i = 4\n",
    "data.to_csv('lose_money_'+str(i)+'.csv')\n",
    "print('Преобразование завершено!')\n",
    "accuracy_error(data,data_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение модели основываясь на первом годе(стандартном) ≈ 90%\n",
    "Простое сложение отрицательного накопления средств для одного банкомата за неделю\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head() файл 'lose_money_4.csv' будет ответом насколько необходимо наполнять банкоматы в год\n",
    "если же взять файл 'array_copy.csv', то можно рассчитать сколько необходимо напонять банкоматы в течении дня, недели, месяца\n",
    "\n",
    "В год data = array_copy[array_copy['operation'] == '-'].groupby(['nomber_terminal'])['money'].sum()\n",
    "\n",
    "В день data = array_copy[array_copy['operation'] == '-'].groupby(['nomber_terminal','day'])['money'].sum()\n",
    "\n",
    "Вычислить для недели сложней, т.к. мы не знаем какой год и не знаем как правильно будет сгруппировать по числам\n",
    "\n",
    "В месяц data = array_copy[array_copy['operation'] == '-'].groupby(['nomber_terminal','month'])['money'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дополнительно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В дальнейшем, для более точного ответа, можно учитывать пользователей, которые постоянно изменяют транзакции. Сделать их классификацию и разбить по классам. Но для этого нужно выделить параметры классов, проще говоря можно использовать метод ближайших соседей в нескольких измерениях...\n",
    "Ниже приведен пример DataFrame, который можно использовать для данного метода\n",
    "!сделал маленький, похожий на настоящий из-за того, что компьютер не потянет 1гб таких вычислений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение модели основанной на классе пользователя.\n",
    "<p>Если пользователь относится к классу с малым количеством транзакций(1-2 за несколько лет), то исключаем его из вычисления.</p>\n",
    "<p>Класс 1: 1-2</p>\n",
    "<p>Класс 2: 2-20</p>\n",
    "<p>Класс 3: 20-90</p>\n",
    "<p>Класс 4: 90+</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id_user - содержится id пользователей\n",
    "#year_т - соержится список всех транзакций пользователя в этот год\n",
    "import random as rd\n",
    "def create_data(N):\n",
    "    f = open('KNN_user_small.csv','w')\n",
    "    f.write('id_user,year_1,year_2,year_3,class_KNN')\n",
    "    f.write('\\n')\n",
    "    for x in tn(range(N)):\n",
    "        a = rd.randint(0,100)\n",
    "        b = rd.randint(0,100)\n",
    "        c = rd.randint(0,100)\n",
    "        sum_all = sum([a,b,c])\n",
    "        if (sum_all>=1)and(sum_all<=2):\n",
    "            class_KNN = '1'\n",
    "        elif (sum_all>=2)and(sum_all<=20):\n",
    "            class_KNN = '2'\n",
    "        elif (sum_all>=20)and(sum_all<=90):\n",
    "            class_KNN = '3'\n",
    "        elif (sum_all>=90):\n",
    "            class_KNN = '4'\n",
    "        f.write(str(x)+','+str(a)+','+str(b)+','+str(c)+','+class_KNN)\n",
    "        f.write('\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_data(10000)\n",
    "data = pd.read_csv('KNN_user_small.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "y = data['class_KNN']\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(data.values, y, test_size=0.3,random_state=17)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=5, random_state=17)\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pred = tree.predict(X_holdout)\n",
    "accuracy_score(y_holdout, tree_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred = knn.predict(X_holdout)\n",
    "accuracy_score(y_holdout, knn_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В конечном итоге на игрушечной выборке, наилучшим методом классификации стал метод решающих деревьев."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
